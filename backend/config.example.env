# ===========================================
# LavenderSentinel Backend Configuration
# ===========================================
# Copy this file to .env and modify as needed

# -------------------------------------------
# Database
# -------------------------------------------
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/lavender_sentinel

# -------------------------------------------
# Redis
# -------------------------------------------
REDIS_URL=redis://localhost:6379/0

# -------------------------------------------
# Qdrant Vector Database
# -------------------------------------------
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=paper_embeddings

# -------------------------------------------
# LLM Configuration (via LiteLLM)
# -------------------------------------------
# Uses nested delimiter __ for sub-settings
# 
# Model format: "provider/model" or just "model" for OpenAI
# See all providers: https://docs.litellm.ai/docs/providers

# === Option 1: OpenAI ===
LLM__MODEL=gpt-4o-mini
LLM__API_KEY=sk-your-api-key-here

# === Option 2: Ollama (local) ===
# LLM__MODEL=ollama/llama3.2
# LLM__API_BASE=http://localhost:11434

# === Option 3: Anthropic Claude ===
# LLM__MODEL=anthropic/claude-3-5-sonnet-20241022
# LLM__API_KEY=sk-ant-your-key

# === Option 4: OneAPI / Custom Proxy ===
# LLM__MODEL=openai/gpt-4o
# LLM__API_BASE=http://your-oneapi-server:3000/v1
# LLM__API_KEY=sk-your-oneapi-key

# === Option 5: Azure OpenAI ===
# LLM__MODEL=azure/your-deployment-name
# LLM__API_BASE=https://your-resource.openai.azure.com
# LLM__API_KEY=your-azure-key

# === Option 6: Groq (fast inference) ===
# LLM__MODEL=groq/llama3-70b-8192
# LLM__API_KEY=gsk_your-groq-key

# === LLM Advanced Options ===
LLM__TEMPERATURE=0.7
LLM__MAX_TOKENS=2000
LLM__TIMEOUT=60

# -------------------------------------------
# Embedding Configuration
# -------------------------------------------
# === Option 1: Local (sentence-transformers, default) ===
EMBEDDING__MODEL=BAAI/bge-base-en-v1.5
EMBEDDING__DIMENSION=768
EMBEDDING__USE_LITELLM=false

# === Option 2: OpenAI Embedding (via LiteLLM) ===
# EMBEDDING__MODEL=text-embedding-3-small
# EMBEDDING__API_KEY=sk-your-api-key
# EMBEDDING__DIMENSION=1536
# EMBEDDING__USE_LITELLM=true

# === Option 3: Ollama Embedding (via LiteLLM) ===
# EMBEDDING__MODEL=ollama/nomic-embed-text
# EMBEDDING__API_BASE=http://localhost:11434
# EMBEDDING__DIMENSION=768
# EMBEDDING__USE_LITELLM=true

# -------------------------------------------
# CocoIndex (optional)
# -------------------------------------------
# COCOINDEX_DATABASE_URL=postgresql://postgres:postgres@localhost:5432/lavender_sentinel
